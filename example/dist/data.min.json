{"collectionMetadata":{"baseUrl":"https://s3-us-west-2.amazonaws.com/levi-portfolio-media","thumbnailName":"thumbnail.png","thumbnailDimensions":{"width":128,"height":128},"logoName":"logo.png"},"posts":[{"id":"anvato","titleShort":"Anvato","titleLong":"Anvato","urls":{"homepage":"http://anvato.com"},"jobTitle":"Software Engineer","date":{"start":"2013","end":"2014"},"categories":["work","web","front-end","android","java","roku","windows-phone","c-sharp","video","data-driven"],"images":[{"fileName":"screenshot1.png","description":"The Anvato web video player."},{"fileName":"screenshot4.png","description":"The Anvato web video player with the preview ribbon open while the user scrubs along the seek bar."},{"fileName":"screenshot5.png","description":"The Anvato web video player with the preview popup open while the user hovers over the seek bar."},{"fileName":"screenshot3.png","description":"The Anvato web video player with the volume control expanded."},{"fileName":"screenshot2.png","description":"The splash screen for the Anvato web video player."}],"videos":[],"content":"_[Anvato][main-url] provides the live and on-demand video management, analytics, syndication, and tracking features\nalong with video player SDKs for iOS, Android, and web._\n\nLevi developed HTTP Live Streaming video-player SDKs for the HTML5, Windows Store, Windows Phone, Roku, and Android\nplatforms to match detailed specifications from clients including Fox, NBC, and Univision.\n\nThe HTML5 player SDK loaded and played four-times faster than that of Anvato’s leading competitor.\n\nThe combined Anvato player SDKs drew more than 528,000 viewers per minute during the 2014 SuperBowl, making it the\nmost-viewed single sports event ever delivered online.\n\n[main-url]: http://anvato.com"},{"id":"benlindseydesign.com","titleShort":"Portfolio\nWebsite:\nDesigner","titleLong":"Portfolio for an Industrial Designer","urls":{"homepage":"http://benlindseydesign.com","github":"https://github.com/levisl176/benlindseydesign.com"},"jobTitle":"","date":{"start":"2014","end":"2015"},"categories":["side-project","web","web-site","front-end"],"images":[],"videos":[],"content":"_**This project is a work in progress**_\n\nThis website is a professional portfolio for Ben Lindsey.\n\n[main-url]: http://benlindseydesign.com"},{"id":"chess","titleShort":"Web App:\nChess","titleLong":"Chess","urls":{"demo":"http://jackieandlevi.com/chess","github":"https://github.com/levisl176/chess"},"jobTitle":"","date":"2013","categories":["side-project","web","app","front-end","game"],"images":[{"fileName":"screenshot1.png","description":"Gameplay screenshot: Directions for the game are shown below the board."},{"fileName":"screenshot2.png","description":"Gameplay screenshot: After clicking on a piece, you must move that piece. Hovering over valid tiles to move the piece to, will cause the tile to turn green. Invalid tiles will turn red. Tiles will turn yellow if the move would take an enemy piece. If there are no valid moves for a piece, it is not selectable in the first place."},{"fileName":"screenshot3.png","description":"Gameplay screenshot: After clicking on a piece, you must move that piece. Hovering over valid tiles to move the piece to, will cause the tile to turn green. Invalid tiles will turn red. Tiles will turn yellow if the move would take an enemy piece. If there are no valid moves for a piece, it is not selectable in the first place."},{"fileName":"screenshot4.png","description":"Gameplay screenshot: After clicking on a piece, you must move that piece. Hovering over valid tiles to move the piece to, will cause the tile to turn green. Invalid tiles will turn red. Tiles will turn yellow if the move would take an enemy piece. If there are no valid moves for a piece, it is not selectable in the first place."},{"fileName":"screenshot5.png","description":"Gameplay screenshot: The current gameplay status is shown above the board."},{"fileName":"screenshot7.png","description":"Gameplay screenshot: The current gameplay status is shown above the board."},{"fileName":"screenshot10.png","description":"Gameplay screenshot: Casteling is supported (before castling)."},{"fileName":"screenshot11.png","description":"Gameplay screenshot: Casteling is supported (after castling)."},{"fileName":"screenshot9.png","description":"Gameplay screenshot: Even the special rule for en passant captures is supported."},{"fileName":"screenshot6.png","description":"Gameplay screenshot: Pawns can be promoted when reaching the far edge of the board."},{"fileName":"screenshot8.png","description":"Gameplay screenshot: Check mate conditions are also calculated."}],"videos":[],"content":"#### A simple, two-player game of chess\n\nLevi developed this app in a day. It includes a button to generate a random valid play for the current player.\n\nIt currently support game play across remote machines, but Levi plans on implementing this in the future. It currently\ndoes not support an AI player, but Levi also plans on implementing a simple form of this in the future.\n\n[main-url]: http://jackieandlevi.com/chess"},{"id":"dancing-spokes","titleShort":"Web Doodle:\nDancing\nSpokes","titleLong":"Dancing Spokes","urls":{"demo":"http://jackieandlevi.com/dancing-spokes","github":"https://github.com/levisl176/dancing-spokes","codepen":"http://codepen.io/levisl176/pen/Cktif"},"jobTitle":"","date":"2014","categories":["side-project","web","front-end","svg","doodle","tiny","animation"],"images":[{"fileName":"screenshot1.png","description":"The color of each spoke is always shifting to another random value. At any given point, the hue, saturation, and lightness components of the spoke colors are each constrained to a random global range. This creates an interesting effect with independently fluctuating colors that almost always seem cohesive."},{"fileName":"screenshot2.png","description":"The color of each spoke is always shifting to another random value. At any given point, the hue, saturation, and lightness components of the spoke colors are each constrained to a random global range. This creates an interesting effect with independently fluctuating colors that almost always seem cohesive."}],"videos":[],"content":"#### Fun with SVG animations and dancing sticks of light!\n\nThe color of each spoke is always shifting to another random value. At any given point, the hue, saturation, and\nlightness components of the spoke colors are each constrained to a random global range. This creates an interesting\neffect with independently fluctuating colors that almost always seem cohesive.\n\n\n[main-url]: http://jackieandlevi.com/dancing-spokes"},{"id":"dietary-data-recording-system","titleShort":"Android App:\nRecording\nSystem","titleLong":"Dietary Data Recording System","urls":{"homepage":"http://ee.washington.edu/research/seal","published":"http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5766890&isnumber=5766834&url=http%3A%2F%2Fieeexplore.ieee.org%2Fstamp%2Fstamp.jsp%3Ftp%3D%26arnumber%3D5766890%26isnumber%3D5766834"},"jobTitle":"Student Researcher (Software Engineer)","date":{"start":"2010","end":"2011"},"categories":["work","school","research","android","java","app","uw"],"images":[{"fileName":"ddrs-app-screenshots.png","description":"A few of the many different screens of the DDRS app."},{"fileName":"meal-review.png","description":"This screen lets the user review all of the different data they recorded for a given meal."},{"fileName":"photo1.jpg","description":"This photo shows the complete device in the process of recording a video of a meal. It is important for the device to rotate around the meal, so that video captures multiple perspectives of the food."},{"fileName":"photo2.jpg","description":"This photo shows the complete device in the process of recording a video of a meal. It is important for the device to rotate around the meal, so that video captures multiple perspectives of the food."},{"fileName":"video-screen.png","description":"This is the screen that prompts the user to record a video of their food."},{"fileName":"starting-screen.png","description":"This is the home screen of the DDRS app."},{"fileName":"device2.png","description":"Levi also created a second app that was used for internal testing of the video-based volume-calculation algorithm."}],"videos":[],"content":"During his undergraduate studies at the University of Washington, Levi spent more than a year working with\n[Professor Alexander Mamishev][mamishev-url] in the [Sensors Energy and Automation Laboratory][seal-url]. The lab had\nbeen hired by the [Fred Hutchinson Cancer Research Center][fred-hutch-url] to create a Dietary Data Recording device\nthat would better record the dietary intake of their study participants.\n\nThe lab's work revolved around the development of an application that ran on Android devices. Levi was the sole\ndeveloper for this.\n\n## Features\n\nSome of the application's functionalities included:\n\n- Recording accelerometer and magnetometer data and associating them with individual video frames in order to analyze\nthe volume of food\n- Firing a laser grid via an external, custom-made, Bluetooth-compatible device\n- Recording and playing audio and video\n- Scanning barcodes\n- Compressing, uploading, and downloading data from the databases on our server\n- Recording dietary info in an SQLite database\n- Parsing SQL data to and from an XML file\n\n## Paper\n\nLevi co-authored a paper on this research entitled [A Pervasive Dietary Data Recording System][paper-url].\n\n### Abstract\n\n> The purpose of this research is to determine how beneficial the use of real-time, computer-mediated dietary data\nrecording can be in medical studies. Current methods of dietary tracking and assessment typically involve paper and \npencil food diaries and/or periodic dietary interviews, and these tend to be imprecise, yielding inconclusive results \nas to how a study participant’s diet affects his or her health. Reasons for this imprecision include participant bias,\nerrors in the participant’s memory, errors in the participant’s judgment of food quantities, and underreporting from\nthe participant. The use of computer technology should be able to remedy many of these problems. This project focuses\non creating a device based on mobile phones and hand-held computers to record a participant’s dietary intake. This\nDietary Data Recording System (DDRS) will serve as a convenient method for real-time documentation of a participant’s\nintake, and will allow the participant to record both an audio and a visual description of their food. A fundamental\naspect of DDRS is the use of a laser-generated grid of distances in coordination with stereo-optic images for the\ndetermination of food volume. This device should provide confirmation as to whether real-time computer-assisted\nrecording of dietary data is manageable and accurate.\n\n[mamishev-url]: http://ee.washington.edu/faculty/mamishev/\n[seal-url]: http://ee.washington.edu/research/seal/\n[fred-hutch-url]: http://fredhutch.org/en.html\n[paper-url]: http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5766890&isnumber=5766834&url=http%3A%2F%2Fieeexplore.ieee.org%2Fstamp%2Fstamp.jsp%3Ftp%3D%26arnumber%3D5766890%26isnumber%3D5766834"},{"id":"fat-cat-chat","titleShort":"Web App:\nIRC-Like\nChat","titleLong":"Fat Cat Chat","urls":{"demo":"http://jackieandlevi.com/fat-cat-chat","github":"https://github.com/levisl176/fat-cat-chat"},"jobTitle":"","date":"2014","categories":["side-project","web","app","web-sockets","socket.io","node.js","express","back-end","front-end"],"images":[{"fileName":"screenshot5.png","description":"All of the users currently in a chat room are shown in the right-side panel. Your user name is shown with an asterisk. Hyperlinks can be included within chat messages either by entering a valid URL&mdash;including the protocol&mdash;or by using the special link command."},{"fileName":"screenshot1.png","description":"Private chats are shown in a small, collapsible panel at the bottom of the screen. The other sections of the page are included within accordian-style, collapsible panels."},{"fileName":"screenshot4.png","description":"Each client is kept up-to-date with a manifest of all current rooms and users. Clicking on either a room name or a user name, in any context, will open the corresponding public or private panel, respectively."},{"fileName":"screenshot6.png","description":"There are three buttons at the top of the screen that let you change your chat name, create new rooms, and add new bots to chat with. The bots will send you emoticons, links to funny cat GIFs, and random cat facts."},{"fileName":"screenshot2.png","description":"This app includes a collection of cat-themed emoticons!"},{"fileName":"screenshot3.png","description":"This app includes many standard IRC commands."}],"videos":[],"content":"#### An IRC-like chat server and web client application\n\nLevi built this app in order to hone his server-side skills and to learn about web sockets.\n\n## Features\n\nSome features of this chat application include:\n\n- Private and room chat areas\n- Bots to chat with in case your feeling lonely\n- Syntax highlighting and link injection for user names, room names, and command names\n- The ability to include links in chat messages\n- Custom cat-themed emoticons\n- Numerous fun facts and [GIFS][cat-gif-url] about cats\n- Many commands including:\n    - `/help`\n    - `/rooms`\n    - `/join`\n    - `/msg`\n    - `/nick`\n    - `/ping`\n    - `/ignore`\n    - `/leave`\n    - `/quit`\n    - `/link`\n\n## Acknowledgements / Technology Stack\n\nThe technology stack for this project includes:\n\n- [Node.js][node-url]\n- [Socket.IO][socket-io-url]\n- HTML5/CSS3/JavaScript\n\n\n[main-url]: http://jackieandlevi.com/fat-cat-chat\n[cat-gif-url]: http://25.media.tumblr.com/0798843644c862737ce1258821b5938a/tumblr_mnba38vUWI1qzcv7no1_400.gif\n[node-url]: http://nodejs.org/\n[socket-io-url]: http://socket.io/"},{"id":"generator-meanie","titleShort":"MEAN-stack\nGenerator","titleLong":"MEAN-stack Yeoman Generator with gulp","urls":{"npm":"https://npmjs.org/package/generator-meanie","github":"https://github.com/levisl176/generator-meanie"},"jobTitle":"","date":{"start":"2014","end":"2015"},"categories":["side-project","web","mean-stack","front-end","back-end","mongodb","express","angularjs","node.js","gulp.js","yeoman","npm","library"],"images":[{"fileName":"screenshot4.png","description":"This Yeoman generator includes many prompts that help to customize the boilerplate of your application."},{"fileName":"screenshot1.png","description":"The generated project includes gulp tasks to help tackle many common build problems. Each gulp task is separated into its own individual file and then included by the main gulpfile.js. This obeys the SRP and helps to keep things modular."},{"fileName":"screenshot3.png","description":"The generated project includes a front-end file structure that closely follows the Best Practice Recommendations for Angular App Structure, but with a few additional logical sub-divisions."},{"fileName":"screenshot2.png","description":"The generated project includes a server file structure that has been separated into distinct functional blocks."}],"videos":[],"content":"[![License Status][license-image]][license-url]\n[![NPM version][npm-image]][npm-url]\n[![Downloads Status][downloads-image]][downloads-url]\n[![Build Status][travis-image]][travis-url]\n[![Dependency Status][depstat-image]][depstat-url]\n[![Flattr this git repo][flattr-image]][flattr-url]\n\n_[MEAN stack][mean-url] generator for [Yeoman][yeoman-url] with [gulp][gulp-url]. Follows the \n[Best Practice Recommendations for Angular App Structure][angular-best-practices-url], and, in general, attempts to \nfollow best practices throughout._\n\n## What this is\n\n- **Modular**: The main goal of this generator is to create a highly componentized file structure for both \n  [front-end][angular-best-practices-url] and server-side code. This helps to keep your code modular, scalable, and \n  easier to understand.\n- **Gulp tasks**: This includes a wide array of gulp tasks for optimizing front-end performance and streamlining your \n  development process.\n- **App infrastructure**: This creates a comprehensive boilerplate infrastructure for a end-to-end web application \n  using the MEAN stack. This likely includes some extra bells and whistles that you may not want to include in your \n  particular app. The goal of this project is to promote development through _subtractive_ synthesis. What this means \n  is that, hopefully, this generator creates infrastructure that will handle most of the high-level problems in your \n  web app, in addition to providing some other common features that you will likely remove.\n- **Tests**: This includes a testing infrastructure using the [Karma][karma-url] test runner and the \n  [Jasmine][jasmine-url] test framework for testing the front-end code.\n- **SASS**: This uses the [SASS][sass-url] stylesheet language.\n- **UI-Router**: This uses the [UI-Router][ui-router-url] library for more powerful front-end routing and state \n  management in Angular.\n\n## Why use this generator instead of one of the many other options?\n\nMaybe you shouldn't! Check out the file structure, the gulp tasks, and the various libraries and tools that are used \nin this project. If these are all aspects that you agree with, then please try this generator out! Otherwise, there \nare many other great generators out there for you to use. Addy Osmani has an [excellent article][addy-osmani-url] \ndescribing MEAN-stack development and a quick survey of some of the more popular generators and boilerplate options \nfor it. Each of these options have different benefits and each option uses a different set of tools.\n\n## How to use it\n\n```bash\nnpm install -g generator-meanie\nyo meanie\n```\n\nSee the [getting set up guide][getting-set-up-url] for a step-by-step walkthrough for setting things up and\nrunning.\n\n## Technology stack / acknowledgements\n\nThis project uses technology from a number of third-parties. These technologies include:\n\n- [Node.js][node-url]\n- [AngularJS][angular-url]\n- [MongoDB][mongo-url]\n- [gulp.js][gulp-url]\n- [SASS][sass-url]\n- [Yeoman][yeoman-url]\n- [Git][git-url]\n- Numerous other packages that are available via [NPM][npm-url] (these are listed within the [`package.json`][package.json-url] file)\n\n## Background\n\nThis project is an on-going effort to collect common patterns and processes for developing web apps using the MEAN \nstack and gulp. It is constantly evolving and gaining new features.\n\nThe contents of this project is strongly opinionated. This is all code that was originally developed and tested by \nLevi for his own personal use. That being said, it works great for him, so it will probably work great for you too!\n\nFeedback, bug reports, feature requests, and pull requests are very welcome!\n\n## Next steps\n\nSee the [project roadmap][roadmap-url] for Levi's future plans for this generator.\n\n\n[flattr-url]: https://flattr.com/submit/auto?user_id=levisl176&url=github.com/levisl176/generator-meanie&title=generator-meanie&language=javascript&tags=github&category=software\n[flattr-image]: http://api.flattr.com/button/flattr-badge-large.png\n\n[npm-url]: https://npmjs.org/package/generator-meanie\n[npm-image]: http://img.shields.io/npm/v/generator-meanie.svg?style=flat-square\n[npm-image-old]: https://badge.fury.io/js/generator-meanie.png\n\n[travis-url]: https://travis-ci.org/levisl176/generator-meanie\n[travis-image]: http://img.shields.io/travis/levisl176/generator-meanie/master.svg?style=flat-square\n[travis-image-old]: https://secure.travis-ci.org/levisl176/generator-meanie.png?branch=master\n\n[coveralls-url]: https://coveralls.io/r/levisl176/generator-meanie\n[coveralls-image]: http://img.shields.io/coveralls/levisl176/generator-meanie/master.svg?style=flat-square\n[coveralls-image-old]: https://img.shields.io/coveralls/levisl176/generator-meanie.svg?style=flat\n\n[depstat-url]: https://david-dm.org/levisl176/generator-meanie\n[depstat-image]: http://img.shields.io/david/levisl176/generator-meanie.svg?style=flat-square\n[depstat-image-old]: https://david-dm.org/levisl176/generator-meanie.svg\n\n[license-url]: https://github.com/levisl176/generator-meanie/blob/master/LICENSE\n[license-image]: http://img.shields.io/npm/l/generator-meanie.svg?style=flat-square\n\n[downloads-url]: https://npmjs.org/package/generator-meanie\n[downloads-image]: http://img.shields.io/npm/dm/generator-meanie.svg?style=flat-square\n\n[getting-set-up-url]: https://github.com/levisl176/generator-meanie/blob/master/docs/getting-set-up.md\n[roadmap-url]: https://github.com/levisl176/generator-meanie/blob/master/docs/roadmap.md\n[package.json-url]: https://github.com/levisl176/generator-meanie/blob/master/package.json\n[bower.json-url]: https://github.com/levisl176/generator-meanie/blob/master/bower.json\n\n[angular-best-practices-url]: https://docs.google.com/document/d/1XXMvReO8-Awi1EZXAXS4PzDzdNvV6pGcuaF4Q9821Es/pub\n[mean-url]: http://en.wikipedia.org/wiki/MEAN\n[yeoman-url]: http://yeoman.io/\n[gulp-url]: http://gulpjs.com/\n[node-url]: http://nodejs.org/\n[angular-url]: https://angularjs.org/\n[mongo-url]: https://mongodb.org/\n[sass-url]: http://sass-lang.com/\n[git-url]: http://git-scm.com/\n[npm-url]: http://npmjs.org/\n[bower-url]: http://bower.io/\n[traceur-url]: https://github.com/google/traceur-compiler\n\n[karma-url]: http://karma-runner.github.io/0.12/index.html\n[jasmine-url]: http://jasmine.github.io/2.0/introduction.html\n[protractor-url]: http://angular.github.io/protractor/#/\n[mocha-url]: http://mochajs.org/\n[chai-url]: http://chaijs.com/\n[sinon-url]: http://sinonjs.org/\n\n[ui-router-url]: https://github.com/angular-ui/ui-router\n[passport-url]: http://passportjs.org/\n\n[addy-osmani-url]: http://addyosmani.com/blog/full-stack-javascript-with-mean-and-yeoman/"},{"id":"gesture-recognizer","titleShort":"Gesture\nRecognition","titleLong":"Gesture Segmenter and Recognizer","urls":{"github":"https://github.com/levisl176/stroke-recognition"},"jobTitle":"","date":"2013","categories":["school","research","c-sharp","app","pen"],"images":[{"fileName":"canvas-ink-sigma-instance.png","description":"The program with a sigma shape drawn by the user. The system parameters can be seen on the right. The recognizer in this case has been trained on the sample student data with a hold out of first and sixth instances of each shape from each user. The system recognizes the current canvas ink as a sigma shape."},{"fileName":"directional-bitmaps-sigma-instance.png","description":"The directional pixel values for the ink shown in the previous image."},{"fileName":"directional-bitmaps-sigma-template.png","description":"The directional bitmaps for the sigma shape class template. More intense coloration represents higher probabilities."},{"fileName":"directional-bitmaps-1-2-instance-and-template.png","description":"The directional pixel values for a holdout shape overlaid on top of the directional bitmaps for the shape class template to which it was matched."},{"fileName":"recognition-stats-1-2-instance.png","description":"The recognition details for the shape instance shown in the previous image."},{"fileName":"average-results.png","description":"A confusion matrix showing the average results from an 18-fold cross-validation with single-user holdouts."}],"videos":[{"videoHost":"youtube","id":"xxBeSKijSSw","description":"A walkthrough of Levi's stroke segmentation functionality."}],"content":"_Levi developed a novel algorithm for real-time gesture recognition from ink data. This was extended from work done in\na UCR course on Pen-Based Computing algorithms and techniques._\n\n## An Inductive Image-Based Recognizer Using Directional Bitmap Templates\n\n### Contents\n\n- The Algorithm\n- Strengths\n- Weaknesses\n- Improvements\n- Performance\n- Additional Features\n\n### The Algorithm\n\nThe general idea of the algorithm is to first create four template bitmaps to represent the ink directional\nprobability of a given shape class, then an unknown shape instance is classified as the class whose directional\ntemplates it most closely matches.\n\n#### Preprocessing\n\nFirst, angle values are computed for all points in all strokes in a given shape instance. These angles are based off\nzero degrees along the horizontal axis. The angle value for a point is calculated as the average of the angles of the\nline segments connecting that point to its previous and next neighbors. These angles are then convoluted with a\nGaussian smoothing kernel.\n\nNext, the given shape instance is uniformly scaled and translated so that its x and y coordinate values range from 0\nto 1. It is also translated so that it is centered in this hypothetical, square, 1x1 canvas.\n\nDirectional pixel values are then computed for the given shape instance. There are four directional components\nassociated with each pixel&mdash;the lines along 0&deg;, 45&deg;, 90&deg;, and 135&deg;. The value of a point for each\nof these four directions is 1 if the angle is different by 0&deg;, 0 if the angle is different by 45&deg; degrees or\nmore, and linearly interpolated between 0 and 1 for angles differing by 0&deg;-45&deg;. Note that these directions\nalso match with their opposites; i.e., if a point has an angle of 215&deg;, then it has a difference of 0&deg; with\nthe 45&deg; line, and its value for its 45&deg; directional pixel is 1.\n\nThe entire bitmap region is not stored for each shape instance; in order to save space and time, a mapping from pixel\nindices to directional intensity values is created, and this mapping contains a key for a given pixel if and only if\nthe shape instance contains a point in that pixel. There are actually four such mappings for each shape instance&mdash;\none for each of the four directions. These mappings are created by looping over each of the points, determining in\nwhich pixel a point lies, and storing the four directional values of this point at this pixel index within the four\nmappings. If multiple points in a shape instance have values for the same direction in the same pixel, then the\nlargest value is saved.\n\nThe discretization of ink means that we have two special cases to consider: when a single pixel contains multiple\nconsecutive points, and when the line segment between two consecutive points intersects a pixel in which neither point\nactually lies. The former case is actually handled well with the aforementioned policy of saving a pixel's maximal\nintensity value for each direction. An alternative approach for this could have been to use the average angle values\nfor consecutive points lying within the same pixel, but this causes a good deal of information to be lost within\npixels containing high curvature&mdash;i.e., corners. The latter case could be handled robustly by calculating the\nintermediate pixels via the Bresenham line algorithm, but the lost pixels become less significant with more training\nexamples. Also, a 3x3 Gaussian smoothing kernel is used to smooth the final values of the templates. However, these\ntwo points do not address the lost pixels from an unknown shape instance being recognized, and further research could\nbe performed to determine whether the application of the Bresenham line algorithm would increase recognition accuracy.\n\n#### Training\n\nAfter each shape instance has been preprocessed, actually creating the templates is a simple process. For each shape\nclass, four complete bitmaps are created&mdash;one for each direction&mdash;and then all of the pixel intensity values\nfor each of the training shape instances are added together into the appropriate bitmaps. Each pixel in each bitmap is\nthen normalized by the number of training instances for the given shape class template. Finally, a 3x3 Gaussian\nsmoothing kernel is used to smooth the final values of each of the directional bitmaps for each template.\n\n#### Recognition\n\nTo recognize a given unknown shape instance, a simple distance metric is used, and the shape is classified as \nwhichever class yields the smallest distance. This distance between a shape instance and a class template is computed \nas\n\n![Shape-class distance equation][shape-class-distance-equation-image]\n\nwhere _I_ is the list of the pixel indices&mdash;i.e., keys&mdash;in the pixel indices to directional intensity values\nmappings, _s<sub>&theta;i</sub>_ is the directional intensity value from the &theta; directional mapping of the pixel\nat index _i_ for the unknown shape instance, _t<sub>&theta;i</sub>_ is the directional intensity value from the\n&theta; directional bitmap of the pixel at index _i_ for the shape class template, _n<sub>s</sub>_ is the number of\npixels containing ink for the unknown shape instance, _n<sub>t</sub>_ is the average number of pixels containing ink\nfor the shape class template, and _w_ is a weight parameter.\n\nThe term relating to the number of pixels containing ink is important, because this distance metric only considers\npixels which are covered by the unknown shape instance. To understand why this is a problem, consider the example of\nthe unknown shape instance being the letter P, and there are templates both for the letter P and the letter R.\nBecause the distance only considers the pixels from the shape instance P, the P and R templates will be found to have\nroughly the same distance. This term for the number of pixels containing ink allows the distance metric to match the P\nshape instance more closely to the P template than the R template.\n\nIt may seem that rather than using this term for the number of pixels containing ink, that the distance metric could \nsimply sum over all of the pixels in the template bitmap rather than only over the pixels covered by the shape \ninstance, but this leads to its own problem. This would mean that whichever class template contains the least\nink&mdash;in our case '-'&mdash;would nearly always be found to have the lowest distance.\n\n#### Parameters\n\n_w_ = 0.09\ntemplate side length (they are square) = 14\nnumber of smoothing iterations for the templates = 3\nnumber of smoothing iterations for the point angle values = 1\n\nThese values have been selected by hand.\n\n### Performance\n\nIn order to test this algorithm, a shape collection was compiled from 18 people each drawing 15 shapes 5 times with a\nfew instances being lost due to collection error.\n\nThen an 18-fold cross-validation was performed with single-user hold outs. The averages from this test are presented\nin this confusion matrix.\n\n![Average results][average-results-image]\n\n_***NOTE: this screen shot should instead say \"18-fold\"**_\n\n### Strengths\n\nThe largest strength of this recognition algorithm is that it is extremely fast both to train and to recognize. It \ntook, on average, 0.36 to perform the 18-fold cross-validation, 0.02 seconds to train, and 0.00006 seconds to \nrecognize a shape instance.\n\nThis algorithm is scale invariant.\n\n### Weaknesses\n\nThis algorithm is rotationally variant, so it would not perform well with a system in which rotation mattered.\n\nThis algorithm does not fully take into account the conditional probabilities of the ink. The templates naturally \nrepresent a form of Gaussian probability for ink around a segment of the shape class&mdash;i.e., there is a higher \nprobability of the ink in an instance of the shape class lying in the center of the segment of the template than off \nto either side of the segment. However, given that a point in an instance of the shape class does lie off to one side \nof a segment of the shape class template, it is much more likely that the next point also will lie off to that side, \nand much less likely that the next point will lie off to the other side. This algorithm does not take advantage of \nthis conditional probability.\n\n### Improvements\n\nThis algorithm could be extended to become rotationally invariant. This could possibly be done by rotating each shape \ninstance according to an indicative angle from the centroid to the furthest point from the centroid.\n\nThe conditional ink probability&mdash;addressed in the weaknesses section&mdash;could be taken advantage of with a\n\"super pixel\" scheme. In this scheme, each pixel in each directional bitmap could contain four additional mxm\nsub-bitmaps of pixel values. These sub-bitmaps would represent the conditional directional ink probabilities of the\nneighbors of the given center pixel. Adapting the training of the templates for these bitmaps of super pixels and the\ndistance metric would be a fairly straightforward extension of their current versions. However, this super-pixel\nscheme would have a much higher time and space complexity.\n\n### Additional Features\n\n![Directional bitmaps for the sigma-class template][directional-bitmaps-sigma-template-image]\n\nThis shows the directional bitmaps for the sigma shape class template. More intense coloration represents higher probabilities.\n\n![The original ink on the canvas for an instance of the sigma shape][canvas-ink-sigma-instance-image]\n\nThis shows the program with a sigma shape drawn by the user. The system parameters can be seen on the right. The recognizer in this case has been trained on the sample student data with a hold out of first and sixth instances of each shape from each user. The system recognizes the current canvas ink as a sigma shape.\n\n![Directional bitmaps showing an instance of the sigma shape][directional-bitmaps-sigma-instance-image]\n\nThis shows the directional pixel values for the ink shown in the previous image.\n\n![Directional bitmaps showing data for both an instance and the template of the 1/2 shape][directional-bitmaps-1-2-instance-and-template-image]\n\nThis shows the directional pixel values for a holdout shape overlaid on top of the directional bitmaps for the shape class template to which it was matched.\n\n![Recognition statistics for an instance of the 1/2 shape][recognition-stats-1-2-instance-image]\n\nThis shows the recognition details for the shape instance shown in the previous image.\n\n\n[shape-class-distance-equation-image]: https://s3-us-west-2.amazonaws.com/levi-portfolio-media/gesture-recognizer/shape-class-distance-equation.png\n[average-results-image]: https://s3-us-west-2.amazonaws.com/levi-portfolio-media/gesture-recognizer/average-results.png\n[directional-bitmaps-sigma-template-image]: https://s3-us-west-2.amazonaws.com/levi-portfolio-media/gesture-recognizer/directional-bitmaps-sigma-template.png\n[canvas-ink-sigma-instance-image]: https://s3-us-west-2.amazonaws.com/levi-portfolio-media/gesture-recognizer/canvas-ink-sigma-instance.png\n[directional-bitmaps-sigma-instance-image]: https://s3-us-west-2.amazonaws.com/levi-portfolio-media/gesture-recognizer/directional-bitmaps-sigma-instance.png\n[directional-bitmaps-1-2-instance-and-template-image]: https://s3-us-west-2.amazonaws.com/levi-portfolio-media/gesture-recognizer/directional-bitmaps-1-2-instance-and-template.png\n[recognition-stats-1-2-instance-image]: https://s3-us-west-2.amazonaws.com/levi-portfolio-media/gesture-recognizer/recognition-stats-1-2-instance.png"},{"id":"hex-grid","titleShort":"Hex Grid","titleLong":"Hex Grid","urls":{"demo":"http://jackieandlevi.com/hex-grid","github":"https://github.com/levisl176/hex-grid"},"jobTitle":"","date":"2014","categories":["side-project","web","front-end","svg","canvas","animation","library","app","data-driven","dat.gui","gulp.js"],"images":[],"videos":[],"content":"#### A dynamic, expandable, animated grid of hexagonal tiles for displaying posts\n\nLevi was bored with the standard grid layout and wanted to play with particle systems and crazy animations. So he made\nhex-grid.\n\n## Features\n\nSome features of this package include:\n\n- A particle system complete with neighbor and anchor position spring forces.\n- An assortment of **persistent** animations that make the grid _exciting to watch_.\n- An assortment of **transient** animations that make the grid _exciting to interact with_.\n- A control panel that enables you to adjust most of the many different parameters of this system.\n- The ability to display custom collections of posts.\n    - These posts will be displayed within individual tiles.\n    - These tile posts can be expanded for more information.\n    - The contents of these posts use standard [Markdown syntax][markdown-url], which is then parsed by the system for\n      displaying within the grid.\n\n## Acknowledgements / Technology Stack\n\nThe following packages/libraries/projects were used in the development of hex-grid:\n\n- [Gulp.js][gulp-url]\n- [Bower][bower-url]\n- [dat.gui][dat-gui-url]\n- [Showdown][showdown-url]\n- Additional packages that are available via [NPM][npm-url] (these are listed within the `package.json` file)\n\n\n[demo-url]: http://www.jackieandlevi.com/hex-grid\n[markdown-url]: http://daringfireball.net/projects/markdown/\n[dat-gui-url]: http://code.google.com/p/dat-gui\n[gulp-url]: http://gulpjs.com\n[bower-url]: http://bower.io\n[npm-url]: https://npmjs.org\n[showdown-url]: https://github.com/showdownjs/showdown"},{"id":"jackieandlevi-profiles","titleShort":"Web App:\nMaterial\nDesign","titleLong":"Profile pages","urls":{"demo":"http://jackieandlevi.com/levi","github":"https://github.com/levisl176/jackieandlevi-profiles"},"jobTitle":"","date":"2014","categories":["side-project","web","app","front-end","angularjs","gulp.js","material-design","animation","data-driven"],"images":[],"videos":[],"content":"#### Profile pages using AngularJS and Material Design\n\n_**This project is a work in progress**_\n\nLevi used [Google's Material Design language][md-url] to create clean styles and natural animations for this project.\n\n_AngularJS, angular-material, angular-ui-router_\n\n\n[main-url]: http://jackieandlevi.com/levi\n[md-url]: http://www.google.com/design/spec/material-design/introduction.html"},{"id":"idean","titleShort":"Idean","titleLong":"Idean","urls":{"homepage":"http://idean.com"},"jobTitle":"UI Developer","date":"2014","categories":["work","web","front-end","back-end","user-experience","data-driven","mean-stack","angularjs","node.js","mongodb","express","gulp.js","grunt","d3.js","svg","php"],"images":[{"fileName":"idean-hawaii.jpg","description":"Hawaii!! Idean flew their employees to Oahu for their annual retreat."},{"fileName":"palo-alto-studio.jpg","description":"Idean's office at their head quarters in Palo Alto. The home-like atmosphere of the house definitely reflects the friendly and relaxed atmosphere of the company as a whole."},{"fileName":"idean-definition.png","description":"Life's too short for crappy UX!"}],"videos":[{"videoHost":"vimeo","id":"50565896","description":"Idean's introductory video: why a good user experience is important and how Idean can help."},{"videoHost":"vimeo","id":"88468432","description":"Idean's UX Rap!"}],"content":"_[Idean][main-url] is a global design agency dedicated to delivering the best possible User Experience._\n\nLevi used JavaScript to create awesome user experiences across many different projects for many different clients.\n\n### Project A: Enterprise Security-Management Application\n\nLevi developed a high-fidelity prototype for the client’s enterprise security-management application. This included a\nrobust AngularJS framework with an intricate front-end routing mechanism.\n\n_Front and back end: Node.js, AngularJS, MongoDB, Gulp_\n\n### Project B: Enterprise Resource-Management Application\n\nLevi developed a first-iteration of the front-end for the client's enterprise resource-management application. This\nincluded a complex SVG-based workspace.\n\n### Project C: Analytics Dashboard\n\nLevi developed a web portal for analyzing data collected from mobile applications. This included highly configurable\ndata visualizations.\n\n_Front end: AngularJS, D3.js, Gulp_\n\n### Project D: Web Portal for SDK Specifications\n\nLevi developed a web portal for displaying the specifications of the client's RESTful API. This included the ability\nto test out and tweak each of the different API calls directly from the portal. Levi also created a simple test server\nfor handling the requests.\n\n_Front and back end: Node.js, AngularJS, MongoDB, Gulp_\n\n### Project E: Internal Content Management System\n\nLevi developed the infrastructure for an internal content management system.\n\n_Front and back end: Node.js, AngularJS, MongoDB, Grunt_\n\n### Project F: WordPress site\n\nLevi updated and maintained the client's pre-existing WordPress website.\n\n### Project G: Squarespace site\n\nLevi customized the client's pre-existing Squarespace website.\n\n[main-url]: http://idean.com"},{"id":"jackieandlevi.com","titleShort":"Levi's\nPortfolio\nWebsite","titleLong":"My Portfolio Website","urls":{"homepage":"http://jackieandlevi.com","github":"https://github.com/levisl176/jackieandlevi.com"},"jobTitle":"","date":{"start":"2013","end":"2015"},"categories":["side-project","web","website","app","front-end","back-end","mean-stack","node.js","express","angularjs","mongodb","gulp.js","material-design","animation"],"images":[],"videos":[],"content":"#### The personal web site of Jackie and Levi Lindsey\n\nThis site is where Levi tinkers with many different projects. It's basically his playground. And his portfolio.\n\n[main-url]: http://jackieandlevi.com"},{"id":"metabounce","titleShort":"Web Doodle:\nMetabounce","titleLong":"Metabounce","urls":{"demo":"http://jackieandlevi.com/metabounce","github":"https://github.com/levisl176/metabounce","codepen":"http://codepen.io/levisl176/pen/bkmpE"},"jobTitle":"","date":"2014","categories":["side-project","web","doodle","front-end","svg","animation"],"images":[{"fileName":"screenshot1.png","description":"Both the inner and main balls grow and eventually pop with delightful animations. A popping ball will push&mdash;and possibly pop&mdash;neighboring balls."},{"fileName":"screenshot2.png","description":"The balls can be rendered with transparency and multiple gradients that make them resemble iridescent bubbles."},{"fileName":"screenshot3.png","description":"This app includes many parameters that adjust things like: bounce squish intensity, gravity, drag, pop force thresholds, ball growth rates, pop neighbor displacement power, nested balls, ball colors, ball count, ball size, etc."},{"fileName":"screenshot4.png","description":"This app includes many parameters that adjust things like: bounce squish intensity, gravity, drag, pop force thresholds, ball growth rates, pop neighbor displacement power, nested balls, ball colors, ball count, ball size, etc."}],"videos":[],"content":"#### Fun with SVG, balls, and bouncing!\n\nThis is a project in which Levi played around with balls and bouncing. This is just for fun, so enjoy!\n\nThe color of each ball is always shifting to another random value. At any given point, the hue, saturation, and\nlightness components of the ball colors are each constrained to a random global range. This creates an interesting\neffect with independently fluctuating colors that almost always seem cohesive.\n\n\n[main-url]: http://jackieandlevi.com/metabounce\n[codepen-url]: http://codepen.io/levisl176/pen/lqmAE"},{"id":"newtons-pen","titleShort":"Intelligent\nTutoring\nSystem:\nPen","titleLong":"Newtons Pen","urls":{"published":"http://escholarship.org/uc/item/40r3k5v2"},"jobTitle":"Graduate Student Researcher (Software Engineer)","date":{"start":"2012","end":"2013"},"categories":["work","school","research","ucr","c-sharp","java","app","livescribe","pen","data-driven"],"images":[{"fileName":"pen-boundary-stage-work-1.png","description":"A free-body-diagram worksheet showing a student's completed work."},{"fileName":"pen-fbd-worksheet.png","description":"A free-body-diagram worksheet showing a student's completed work."},{"fileName":"pen-prob-desc-worksheet.png","description":"A problem-description worksheet showing problem-specific information in the top region and general buttons for using the system in the bottom region."},{"fileName":"pen-and-paper.png","description":"A Livescribe smartpen with Anoto dot paper"}],"videos":[{"videoHost":"youtube","id":"y8QYhgRrRZk","description":"A narrated demonstrational video explaining how to use the Newton's Pen application."}],"content":"#### An Intelligent Tutoring System running on Window's tablets\n\nIn his graduate studies at the University of California, Riverside, Levi worked with Professor\n[Thomas Stahovich][stahovich-url] in the [Smart Tools lab][stl-url].\n\nLevi led the development of a statics tutorial system, which both helped novice students tackle difficult concepts and\nprovided the lab with key insights into the learning process and how students think.\n\nThis work resulted in the production of two completely different software programs: one which ran on tablet PC\ncomputers with a standard computer interface (_written in C# with WPF_), and one which ran on\n[Livescribe smartpens][livescribe-url] with specially designed paper worksheets (_written in Java_). Both programs\nwere designed with natural user interface as a paramount concern. These programs were deployed to 150 students in an\nintroductory statics course at the University of California, Riverside in the Winter of 2012.\n\nYou can read Levi's thesis at [escholarship.org/uc/item/40r3k5v2][thesis-url].\n\n\n[stahovich-url]: http://www.engr.ucr.edu/faculty/me/stahovich.html\n[stl-url]: http://smarttools.engr.ucr.edu/\n[livescribe-url]: http://livescribe.com/en-us/\n[thesis-url]: http://escholarship.org/uc/item/40r3k5v2"},{"id":"newtons-tablet","titleShort":"Intelligent\nTutoring\nSystem:\nTablet","titleLong":"Newtons Tablet","urls":{"published":"http://escholarship.org/uc/item/40r3k5v2"},"jobTitle":"Graduate Student Researcher (Software Engineer)","date":{"start":"2012","end":"2013"},"categories":["work","school","research","ucr","c-sharp","java","app","tablet","data-driven"],"images":[{"fileName":"boundary-trace-stage-screenshot.png","description":"A screenshot of the program during the boundary-trace stage. At this point, the student is identifying and isolating the individual bodies from complex overall system."},{"fileName":"force-drawing-stage-screenshot.png","description":"A screenshot of the program in during the force-drawing stage."},{"fileName":"error-mode-screenshot.png","description":"A screenshot of the program showing error feedback. During each stage in the problem solving process, the program evaluates the student's work and provides guided feedback for any errors."},{"fileName":"exp-eqn-entry-stage-screenshot.png","description":"A screenshot of the program during the final, equation-entry stage."},{"fileName":"matching-points-from-resampling.png","description":"The Importance of Resampling for Matching Points. In these two examples, the blue points represent the hand-drawn stroke, and the red points represent the boundary of the underlying body. Lines are drawn from a point in one set to the closest point in the other set if the closest point is within the distance threshold. The points with a yellow center represent points that do not have any close matches from the other set. (a) Many of the points from a densely sampled trace stroke will not match any of the points from a sparsely sampled boundary polygon. (b) Resampling the trace and the boundary polygon to the same number of points—40 in this case—greatly increases the likelihood of points having matches."}],"videos":[{"videoHost":"youtube","id":"LAlzil4WsGw","description":"A narrated demonstrational video explaining how to use the Newton's Tablet program."}],"content":"#### An Intelligent Tutoring System running on Window's tablets\n\nIn his graduate studies at the University of California, Riverside, Levi worked with Professor\n[Thomas Stahovich][stahovich-url] in the [Smart Tools lab][stl-url].\n\nLevi led the development of a statics tutorial system, which both helped novice students tackle difficult concepts and\nprovided the lab with key insights into the learning process and how students think.\n\nThis work resulted in the production of two completely different software programs: one which ran on tablet PC\ncomputers with a standard computer interface (_written in C# with WPF_), and one which ran on\n[Livescribe smartpens][livescribe-url] with specially designed paper worksheets (_written in Java_). Both programs\nwere designed with natural user interface as a paramount concern. These programs were deployed to 150 students in an\nintroductory statics course at the University of California, Riverside in the Winter of 2012.\n\nYou can read Levi's thesis at [escholarship.org/uc/item/40r3k5v2][thesis-url].\n\n\n[stahovich-url]: http://www.engr.ucr.edu/faculty/me/stahovich.html\n[stl-url]: http://smarttools.engr.ucr.edu/\n[livescribe-url]: http://livescribe.com/en-us/\n[thesis-url]: http://escholarship.org/uc/item/40r3k5v2"},{"id":"phone-wand","titleShort":"Blind-\nAccessible\nNavigation","titleLong":"Phone Wand","urls":{"googleCode":"https://code.google.com/p/mobileaccessibility/source/browse/#svn%2Ftrunk%2FPhoneWand"},"jobTitle":"","date":"2011","categories":["school","research","uw","android","java","accessibility","google-maps-api","app"],"images":[{"fileName":"fixedinputscreen2.png","description":"This screen presents the current destination. This is essentially a home screen. From here, the user can enter a new destination, find a list of old destinations, find a list of other possible matches for the destination that was typed in the keyboard, or start navigating toward the current destination."},{"fileName":"fixedkeyboard1.png","description":"This screen presents a custom, blind-accessible keyboard. The user can drag a finger over the the buttons to hear them quickly read aloud via TTS."},{"fileName":"fixedroute1.png","description":"While on this screen, the system provides vibrational feedback to guide the user through the route."},{"fileName":"fixeddirections2.png","description":"This screen presents a list of the steps in the current route. The user can drag a finger over the items to hear them read aloud via TTS."},{"fileName":"fixedroutearchive2.png","description":"This screen presents a list of previously entered destinations. The user can drag a finger over the items to hear them read aloud via TTS."},{"fileName":"screen-transition-diagram-small.png","description":"This diagram illustrates all of the different screens of the system and how to navigate from one to another."}],"videos":[{"videoHost":"youtube","id":"qooZe704Ppw","description":"A narrated demonstrational video explaining how to use the Phone Wand application."}],"content":"#### A blind-accessible route-navigation Android application\n\nIn a computer science capstone course on accessibility at the University of Washington, Levi co-developed a\nroute-orienting application that would guide a blind user via vibrational feedback.\n\nThis application would first geocode the user's current location and a user-entered destination and then query the\nGoogle Directions API for a route from the one to the other. This route was then displayed on a map with the user’s\ncurrent location. The user could then rotate the phone around, and the phone would vibrate when pointed in the\ndirection of the current step in the user's route.\n\nThis involved the creation of a completely novel blind-accessible soft keyboard in addition to the implementation of a\ndatabase for storing previously entered destinations.\n\nThe PhoneWand code is open source and online at\n[http://code.google.com/p/mobileaccessibility/source/browse/#svn%2Ftrunk%2FPhoneWand][main-url].\n\n_The following is the final paper from the Phone Wand project._\n\n## Abstract\n\nThe Phone Wand is an Android application for mobile phones that enables a blind user to more easily input and navigate \na walking route. At any time a route has been specified, the phone can hint which direction to walk when the user \nrequests assistance using the phone's built-in compass and vibration: (1) the user requests for help by double tapping \nthe \"magic button\" on an orientation screen, (2) the user moves the phone radially to search for the correct direction \nand (3) the phone vibrates when facing the correct direction to continue on the route. This type of assistance is \nuseful when the user is en route to the next intersection and wishes to verify the current heading along the route, or \nif the user has reached an intersection and wishes to receive the heading to the next intersection. The application \nalso contains features to enable blind-users to more easily input and manage walking routes. This includes a custom \nblind-accessible keyboard implementation to more easily input addresses, a \"slide-rule\" based blind-accessible list of \npreviously entered walking routes, and an ability to save your current location as a new future destination. Such \napplication is useful for blind users navigating noisy, dense, urban city centers where hearing is difficult, the \napplication's non-verbal orientation guidance is effective, and where location sensing tools are most accurate.\n\n## Introduction\n\nNavigating routes can be difficult or time consuming for people who are blind or have low-vision. Navigation \napplications that are not blind-accessible make it especially difficult and time consuming for blind users to navigate \nthe software enter route destination. Another problem is that too much text-to-speech can be obstructive to a blind \npersons most important sense, hearing, taking away focus from actual navigation and listening for hazards. While \nblind-accessible applications often provide an easy interface to input, they often rely too much on text-to-speech \noutput.\n\nThe purpose of the Phone Wand is to minimize text-to-speech related to actual route navigation but keep only the \ntext-to-speech necessary for a functioning blind-accessible application. The Phone Wand replaces verbal navigation \nfeedback with vibrational feedback. This is a relatively new type of interaction that uses orientation as input and \nvibration as output. The concept is simple, (1) the user points the phone 360 degrees around her and (2) the phone \nvibrates when the user is facing the correct direction. This requires minimal text-to-speech as output, solving our \ninformation flooding problem. However, while the heart of our application uses compass and vibration feedback, our \napplication still relies on text-to-speech for blind-accessible text entry, traditional list of directions display and \ngiving application directions.\n\nThe target group for our application includes blind users and low-vision users who can hear. The compass and vibration \nfeedback portion of our application is theoretically blind-deaf-accessible. But, we assume that our target group can \nhear text-to-speech in order to hear application directions and use the touch keyboard to set up routes in our \napplication. Theoretically we could make the application completely blind-deaf accessible if we had an option to \ntranslate our input and output methods into some standard method familiar for blind-deaf users.\n\n## Use Case\n\nHarry is walking to a nearby store on the sidewalk and would like additional help. He pulls out his Android phone and \nlaunches the Phone Wand. After patiently inputting the store's destination, and waiting for the phone to compute the \nroute, he can press the \"magic button\" to enable the compass driven vibrational orientation feedback mode. After \npointing around for a bit, the phone vibrates in the direction he was heading, indicating that he is en route to the \ndestination. Minutes later he reaches an intersection and is unsure of this next direction of travel. Pressing the \n\"magic button\" again, he points the phone around. This time the phone vibrates when he points it to his left. This \nindicates that he should turn left. Harry continues this until he reaches the store, where the phone announces that he \nhas arrived at his destination.\n\n## Related Work\n\nThere has been a lot of work previously done for inventing useful methods of route-finding and navigation for blind \nusers. Most of these previous projects are lacking in some regard such as their accuracy, usability, or availability. \nThere are many projects involving the creation of a novel navigation device, such as the EYECane project, which \ninvolved the creation of a white cane device with an embedded computer and camera, but we will focus rather on\nblind-accessible smart phone route-finding/navigation applications.\n\nMost previous work with smart phone applications involves the use of GPS navigating systems with audio feedback \nsimilar to the systems available for driving. The Sendero Group has created a couple of applications that are similar \nto our project. Their LookAround application has a user interface that is very similar to ours, but it only provides\ninformation on the user's current location; it does not provide route information. Their Mobile Geo application both\nfinds routes and provides information about locations; however, this costs $788, and uses primarily audio feedback.\nThe Iwalk application is another navigation application similar in to ours, but once again, this application's primary\nmethod of user feedback was with audio.\n\nOur application also relies on special accessible methods of text entry and item selection. Our slide rule list item \nselection is based upon an earlier project which allows the user to explore the items by pressing a finger on the item\nand to select it by double tapping it. Our blind accessible touch keyboard was actually invented from scratch and\nemulates no prior method of text entry; the key is spoken when a finger presses onto it and is selected when a finger\nis lifted from it. However, a very similar technique for text entry can be seen in how Apple provides iPhone item\nexploration and selection with their VoiceOver functionality; with VoiceOver, an item is spoken when pressed or slid\nover and is selected with a second touch on the screen.\n\n## Solution\n\nThe purpose of the Phone Wand application is to provide a blind-accessible interface and orientation scheme for\nfinding and navigating walking routes. Hence the Phone Wand uses the Google Directions API to calculate walking routes\nusing the Android location service including network assisted GPS. Orientation output from the Android sensor service\nand vibration features are used for orientation feedback. The Android TextToSpeech (TTS) library is heavily used to\ncommunicate application screen directions to users in a blind-accessible manner. The Phone Wand automatically saves,\npreviously entered routes and provides the ability to save the current location. The slide rule selection method is\nused to display these routes for the users and to display a current list of the walking route directions.\n\n### Destination Input\n\nThe Phone Wand features a custom blind-accessible keyboard for entering destinations. This keyboard was created to\nemulate the familiar iPhone keyboard familiar to many blind users. The user uses the keyboard by holding down on the\nscreen and releasing when the desired letter is called. There is functionality for reading out the entered text,\nbackspace, readout of cursor location, and other features. The done button searches for a route best matching the\nentered text.\n\nSince blind-accessible text entry is still relatively time consuming for users, the Phone Wand automatically saves\npreviously entered destinations in a list. A user can access this blind-accessible list and select a destination\naddress. The list is based on a Slide Rule interaction technique (cite slide rule paper). A user can scan the list\nwith her finger while the phone speaks back what is currently underneath her finger. If the list is longer than the\nscreen, the user can scan for the \"next\" and \"previous\" buttons in the list to navigate the list. When the user finds\nthe desired item, she can double tap to confirm the item, which the phone will then search for a route.\n\n### Navigation Features\n\nAfter a destination has been entered via keyboard or selected from the list of saved addresses, the phone takes the\nuser to a map screen, which displays a route from the current location to the destination. On this screen, there are\nseveral options: (1) recompute a new route from the current location, (2) find a nearby address and save it, (3)\naccess a list of directions, or (4) using the compass and vibration feature.\n\n(1) Recomputing a route is useful when the user is significantly off course from the original route, or otherwise when\nthe user wants to find a fresh route from the current location. The user can accomplish this by swiping upwards. The\nphone downloads a new route using the Google Directions API.\n\n(2) Finding a nearby address and saving it is useful when the user wants to \"bookmark\" the current location for future\nuse. This is accomplished by swiping downwards.\n\n(3) The user can also access a list of directions. The user can swipe right on the map screen to view the list of\ndirections. The list is blind-accessible: it uses the slide rule interaction. Therefore a user can scan through the\nlist and have the phone speak back the directions. This functionality was implemented to give the user another option.\n\n(4) Finally, the user can take advantage of the compass and vibration feature on this screen as detailed in the next\nsection.\n\n### Compass and Vibration\n\nWhile the map screen provides additional features, the compass and vibration mode is the most prominent feature of our\napplication.\n\nTo activate the compass and vibration mode, the user double taps on the map screen. (This gesture is referred to as\nthe \"magic button\" because it turns this mode on and off.) Afterwards, the user can move the phone radially around\nher. The phone vibrates when the user is facing the correct direction. The user should double tap on the map screen\nagain to deactivate the mode and continue walking the direction determined by the phone.\n\nThe intended use of this compass and vibration mode is to check the user's heading at interest points (like\nintersections) along the route, or whenever the user simply needs to verify her heading. Therefore, the user should\nactivate the mode, check her heading, and then deactivate immediately. While one can activate the mode and leave it\nenabled throughout the entire route, it may not be accurate enough to direct the user along the route.\n\nFor effective feedback from the compass, the user should hold the phone parallel to the ground, move the phone\nradially (point the phone 360 degrees around the person), and move the phone slowly. Since the compass is not entirely\naccurate, we advise using this feature to \"check\" the heading occasionally along the route, not to depend on it\nentirely.\n\n## Future Work\n\nWe foresee a few extensions and modifications of the Phone Wand that would be valuable blind and low-vision accessible \napplications.\n\n### Indoor Navigation using RFID Tags\n\nWillis and Helal's paper \"RFID information grid for blind navigation and wayfinding\" lays out the foundations needed\nto use and construct an indoor RFID (Radio Frequency Identification) based indoor navigation system. RFID tags are\ncheap, extremely power efficient devices with immense portability that can hold a small amount of information. They are\nextremely useful in pervasive computing by (literally) attaching computer data to physical objects. Indoor navigation\nis solved by rigging buildings with thousands of RFIDs each containing a small piece of geographical information. The\nadvantage of RFID readers vs. GPS is in the locality of the information that can be encoded in the RFID. The\nconstruction is based on \"mature technology\" so the limiting factors for widespread use of the infrastructure\ntechnology is simply economical feasibility and adoption. With demonstrated success in large corporations and college\ncampuses the technology could be come widespread and worked into building code standards.\n\nIn order for Android to take advantage and drive this potentially navigation changing technology, Android would either\nneed to implement an internal RFID reader or provide some simple cost-effective RFID reader attachment. The limiting\nfactor is hardware. The implications of a Blind indoor navigation tool would be extremely valuable for users to\nnavigate complicated indoor areas with little or no GPS capabilities such as airports, public transportation\nterminals, malls, and stadiums.\n\n### Indoor Navigation using RFID Tags\n\nA useful extension to the Phone Wand would be transferring orientation and vibration feedback to a walking cane via \nBluetooth. A cane is the most natural and useful tool to aid blind people in everyday walking. This extension would \nrequire embedding hardware for compass sensors and vibration directly into a walking cane. There already exists bulky \nand expensive electronic aided canes on the market that use sonar to detect solid obstacles and puddles within a \"zone \nof safety\". But user feedback indicates these tend to be too expensive or non-functional for practical use. With the \nhardware problem solved, a CaneNavigator Android application would allow users to simply enter all route information \ninto the cell phone, then the Bluetooth would activate, and then the cell phone could be placed in the users pocket. \nAll information sensing would then be embedded in the cane and then transferred to the cell phone via Bluetooth. \nInformation would then be processed and vibration signals would transfer from the phone to the cane via Bluetooth.\n\n\n[main-url]: http://code.google.com/p/mobileaccessibility/source/browse/#svn%2Ftrunk%2FPhoneWand"},{"id":"photo-viewer","titleShort":"Web App:\nPhoto Viewer","titleLong":"Photo Viewer","urls":{"demo":"http://jackieandlevi.com/photo-viewer","github":"https://github.com/levisl176/photo-viewer"},"jobTitle":"","date":"2014","categories":["side-project","web","front-end","app","xhr2","animation","data-driven"],"images":[{"fileName":"screenshot3.png","description":"The images for each of the different categories are contained within their own panels. These collapse and expand in an accordian style (only one panel is expanded at a time)."},{"fileName":"screenshot5.png","description":"Clicking on a image thumbnail causes a lightbox to be shown containing a larger version of that thumbnail image."},{"fileName":"screenshot8.png","description":"The image lightbox includes overlay controls for exiting, entering full-screen mode, and navigating to the previous and next images"},{"fileName":"screenshot6.png","description":"The image within a lightbox can be expanded for full-screen viewing. As the higher-resolution image loads, a progress circle is shown with the current image download progress and a phantom background of the mid-sized version of the image."},{"fileName":"screenshot7.png","description":"An image in full-screen mode."},{"fileName":"screenshot1.png","description":"As individual images, or the collection metadata, is loading, a custom progress circle is shown."},{"fileName":"screenshot2.png","description":"After the collection metadata has loaded, the different image categories become available for selection."},{"fileName":"screenshot4.png","description":"The images for each of the different categories are contained within their own panels. These collapse and expand in an accordian style (only one panel is expanded at a time)."},{"fileName":"screenshot9.png","description":"Levi created a stand-alone version of the collapsible grid that was used for displaying the image thumbnails. This grid includes a spring dynamic that creates an interesting animation as the grid collapses of expands."}],"videos":[],"content":"#### A general-purpose photo-viewer application\n\nThis fancy web app is loaded with bells and whistles. A smattering of them includes:\n\n- Expandable, animated photo grids, which display large collections of photo thumbnails\n- A lightbox for conveniently viewing and navigating through medium-sized versions of the images\n- Full-screen mode for viewing and navigating through the original, full-sized versions of the images\n- A very flashy SVG-based progress circle\n- Use of the XHR2 progress event for displaying the download progress of larger images\n\nThis app was originally built to show off the photos from Levi and [Jackie's][jackie-url] wedding.\n\n\n[main-url]: http://jackieandlevi.com/wedding/photos\n[jackie-url]: http://jackieandlevi.com/jackie"},{"id":"rainydayukes.com","titleShort":"Business\nWebsite:\nUkuleles","titleLong":"Business Website for a Hand-Made Ukulele Business","urls":{"homepage":"http://rainydayukes.com"},"jobTitle":"","date":{"start":"2010","end":"2011"},"categories":["side-project","web","web-site","front-end","jquery","php"],"images":[{"fileName":"screenshot1.png","description":"The products page."},{"fileName":"screenshot4.png","description":"The home page features a carousel of delightful images."},{"fileName":"screenshot5.png","description":"The home page features a carousel of delightful images."},{"fileName":"screenshot6.png","description":"The home page features a carousel of delightful images."},{"fileName":"screenshot7.png","description":"The home page features a carousel of delightful images."},{"fileName":"screenshot2.png","description":"The listen page includes videos with songs recorded on Rainy Day Ukes ukuleles. These videos feature the supremely talented baritone Drew Dresdner."},{"fileName":"screenshot3.png","description":"A handmade ukulele company isn't complete without its own signature cocktail!"}],"videos":[],"content":"_[Rainy Day Ukes][main-url] is a web-based handmade ukulele business._\n\nLevi built this website for his friend's business.\n\nAll designs were done by the supremely talented graphic designer [Ryan Maher][ryan-url].\n\n_PHP and jQuery_\n\n[main-url]: http://rainydayukes.com\n[ryan-url]: http://linkedin.com/in/ryanmichaelmaher"},{"id":"progress-circle","titleShort":"Web Doodle:\nProgress\nCircle","titleLong":"Progress Circle","urls":{"demo":"http://jackieandlevi.com/progress-circle","github":"https://github.com/levisl176/progress-circle","codepen":"http://codepen.io/levisl176/pen/ndklu"},"jobTitle":"","date":"2014","categories":["side-project","web","doodle","front-end","svg","tiny","animation"],"images":[{"fileName":"screenshot1.png","description":"The progress circle with its larger radius. The dots revolve in a clockwise direction while the colors of the dots transition in such a way to make the colors appear to transition in a counter-clockwise direction."},{"fileName":"screenshot2.png","description":"The progress circle with its smaller radius. The lightness increases as the radius decreases."}],"videos":[],"content":"#### A progress circle built using SVG\n\nThe progress circle consists of a ring of color-shifting dots.\n\nSpecifically, the dots revolve in a clockwise direction while the colors of the dots transition in such a way to make\nthe colors appear to transition in a counter-clockwise direction.\n\nThis project uses a separate custom animation package Levi developed.\n\n\n[main-url]: http://jackieandlevi.com/progress-circle\n[codepen-url]: http://codepen.io/levisl176/pen/ndklu"},{"id":"shouldihaveanother.beer","titleShort":"Web Doodle:\nBeer?","titleLong":"shouldihaveanother.beer","urls":{"demo":"http://shouldihaveanother.beer","github":"https://github.com/levisl176/shouldihaveanother.beer"},"jobTitle":"","date":"2014","categories":["side-project","web","website","doodle","front-end","canvas","animation","gulp.js"],"images":[{"fileName":"screenshot1.png","description":"This simple web app features randomized delicious beer colors, and delightful animated carbonation."},{"fileName":"screenshot2.png","description":"This simple web app features randomized delicious beer colors, and delightful animated carbonation."},{"fileName":"screenshot3.png","description":"This simple web app features randomized delicious beer colors, and delightful animated carbonation."}],"videos":[],"content":"Levi built and deployed this simple app in a few hours. It exhibits some fun canvas-based animation.\n\nHis main motivation was the availability of fun new top-level domains.\n\nThis simple web app features randomized delicious beer colors, and delightful animated carbonation.\n\n\n[main-url]: http://shouldihaveanother.beer"},{"id":"squared-away","titleShort":"Tile-Matching\nPuzzle\nGame","titleLong":"Squared Away","urls":{"demo":"http://jackieandlevi.com/squared-away","github":"https://github.com/levisl176/squared-away"},"jobTitle":"","date":"2013","categories":["side-project","web","app","front-end","canvas","animation","game"],"images":[{"fileName":"screenshot1.png","description":"Squared Away features a collection of eight different levels&mdash;each with progressively more challenging parameters&mdash;that guide the player in their exploration of the different gameplay features."},{"fileName":"screenshot11.png","description":"Blocks fall from all four sides. Blocks stack and collapse according to rules that closely resemble the familiar game of Tetris. Upcoming blocks are shown for each side with a cool-down progress indicator."},{"fileName":"screenshot10.png","description":"Completed layers show a cool collapsing block sprite-based animation."},{"fileName":"screenshot9.png","description":"Completed layers show a cool collapsing block sprite-based animation."},{"fileName":"screenshot7.png","description":"The game features many configurable parameters."},{"fileName":"screenshot6.png","description":"The main intended method of interaction is with a mouse or touch gestures. Falling blocks can be slid downward, slid from side to side, rotated, and moved to the next quadrant. As a falling block is being manipulated, phantom lines are shown, which help to indicate where a block can be moved in either the downward or lateral directions."},{"fileName":"screenshot5.png","description":"The game can also be played with keyboard input."},{"fileName":"screenshot8.png","description":"The game features background music from the talented Eric Skiff."}],"videos":[],"content":"#### A tile-matching puzzle game\n\nThis web app gave Levi the opportunity to hone his web development skills and to learn the latest features of\nHTML5 and CSS3.\n\nOn the front end, Levi used pure JavaScript without external libraries like jQuery&mdash;with the notable exception of\nSoundJS for cross-browser support for layering audio. On the server side, Levi used Node.js with ExpressJS.\n\n## Gameplay\n\nCore gameplay features:\n\n- Blocks fall from all four sides\n- Blocks stack and collapse according to rules that closely resemble the familiar game of Tetris\n- Upcoming blocks are shown for each side with a cooldown progress indicator\n- Falling blocks can be manipulated with either the mouse or the keyboard if keyboard mode is enabled\n- Falling blocks can be slid downward, slid from side to side, rotated, and moved to the next quadrant\n- As a falling block is being manipulated, phantom lines are shown, which help to indicate where a block can be moved\n  in either the downward or lateral directions.\n- As more layers of blocks are collapsed, the player advances through levels and gameplay becomes more difficult\n  with faster falling blocks and shorter cooldown times.\n- Awesome sound effects and background music.\n\nAdditional optional gameplay features include:\n\n- A mode where only complete layers around the entire center square are collapsed.\n- A mode where blocks fall from the center outward.\n- A special block type that \"settles\" all of the blocks that have landed.\n- A special block type that destroys any nearby block that has landed.\n\n\n[main-url]: http://jackieandlevi.com/squared-away"},{"id":"text-animation","titleShort":"Bower\nPackage:\nText\nAnimation","titleLong":"Text Animation","urls":{"bower":"http://bower.io/search/?q=text-animation","demo":"http://jackieandlevi.com/text-animation","github":"https://github.com/levisl176/text-animation","codepen":"http://codepen.io/levisl176/pen/HGJdF"},"jobTitle":"","date":"2014","categories":["side-project","web","front-end","animation","library","bower","gulp.js"],"images":[{"fileName":"screenshot1.png","description":"Text falling into place with a shadow effect."},{"fileName":"screenshot2.png","description":"Text sliding into place."},{"fileName":"screenshot3.png","description":"Text swirling into place."},{"fileName":"screenshot4.png","description":"Text rolling into place."}],"videos":[],"content":"#### Character-by-character animation of text\n\nThis text-animation package makes it easy to animate the text of any collection of HTML elements. With this package,\neach character animates individually, and it is simple to customize this animation.\n\nThis package is available in the Bower registry as [`text-animation`][bower-url].\n\n### The In-Order Animation Algorithm\n\n1. Iterate through each descendant node in the root element's DOM structure  \n  a. This uses a pre-order tree traversal\n  b. Store the text of each text node along with the parent element and next sibling node\n     associated with the text node\n  c. Fix each descendant element with its original dimensions\n  d. Empty out all text nodes\n2. Iterate through each character and animate them  \n  a. This is now a simple linear iteration, because we flattened the DOM structure in our \n     earlier traversal  \n  b. Animate the character  \n    1. Add the character to a span  \n    2. Insert the span into the character's parent element  \n      a. If the original text node has a next sibling node, then insert this span before that node  \n      b. Otherwise, append this node to the end of the original text node's parent node  \n    4. Run the actual animation of the isolated character  \n  c. Finish animating the character  \n    1. Remove the span  \n    2. Concatenate the character back into the original text node  \n\nThe following three representations of the same DOM structure may help to understand \nhow this algorithm flattens and stores the DOM representation.\n\n#### Original HTML Representation\n\n    <body>\n      H\n      <p>\n        e\n      </p>\n      y\n      <div>\n        D\n        <p>\n          O\n        </p>\n        M\n      </div>\n      !\n    </body>\n\n#### Visual Tree Representation\n\n                                   <body>:Element\n          ________________________________|________________________________\n         /                /               |               \\                \\\n    H:TextNode      <p>:Element      y:TextNode      <div>:Element      !:TextNode\n                         |                  _______________|_______________\n                     e:TextNode            /               |               \\\n                                      D:TextNode      <p>:Element      M:TextNode\n                                                           |\n                                                       O:TextNode\n\n#### JavaScript Object Structure of Text Nodes\n\n    [\n      {\"parentElement\": <body>, \"nextSiblingNode\": <p>,   \"text\": \"H\"},\n      {\"parentElement\": <p>,    \"nextSiblingNode\": null,  \"text\": \"e\"},\n      {\"parentElement\": <body>, \"nextSiblingNode\": <div>, \"text\": \"y\"},\n      {\"parentElement\": <div>,  \"nextSiblingNode\": <p>,   \"text\": \"D\"},\n      {\"parentElement\": <p>,    \"nextSiblingNode\": null,  \"text\": \"O\"},\n      {\"parentElement\": <div>,  \"nextSiblingNode\": null,  \"text\": \"M\"},\n      {\"parentElement\": <body>, \"nextSiblingNode\": null,  \"text\": \"!\"}\n    ]\n\n\n[main-url]: http://jackieandlevi.com/text-animation\n[codepen-url]: http://codepen.io/levisl176/full/HGJdF\n[bower-url]: http://bower.io/search/?q=text-animation"},{"id":"ucr-ta","titleShort":"Teaching\nAssistant","titleLong":"Teaching Assistant","urls":{},"jobTitle":"Teaching Assistant","date":{"start":"2012","end":"2013"},"categories":["school","teaching","c","c++","ucr"],"images":[],"videos":[],"content":"Levi was a teacher's assistant for Software Construction for two quarters and for Intro to Programming for two\nquarters.\n\nBoth of these courses were taught using C++.\n\n## Un-edited end-of-quarter reviews\n\n> He is the best TA i have ever seen.\n\n<!-- -->\n> Levi is always available and helpful to his students. He gives good feedback, which helps the overall learning process. He is kind and always motivates his students. Always in a good mood!\n\n<!-- -->\n> Great TA!. Really nice and knows how to talk to people. Explains the problem and lets you solve it for yourself instead of doing it for you. Made my first CS experience easy.\n\n<!-- -->\n> I don't know how you did it, but managing to run around for 3 hours straight answering all our questions was extremely commendable, and you kept a happy face about it all the time. I'd love to have you as a TA in the future! Thanks for everything\n\n<!-- -->\n> Levi was a really great TA. He is very helpful and approachable as well. He was indeed to go-to person for me whenever I needed help. I understood everything that he said clearly.\n\n<!-- -->\n> Very helpful and easy to approach. He truly cares if the students in his lab and others are learning or not. One of my best TA's so far.\n\n<!-- -->\n> Levi has been a great instructor, and is a very approachable person that as a student I do not hesitate to ask him questions.\n\n<!-- -->\n> You were so helpful and such a good teacher! And super sweet. Thank you!\n\n<!-- -->\n> BEST TA EVER :)"},{"id":"uw-graphics","titleShort":"OpenGL\nAnimations","titleLong":"OpenGL Models and Animations","urls":{},"jobTitle":"","date":"2011","categories":["school","uw","opengl","animation","c++"],"images":[{"fileName":"screenshot1.png","description":"A screenshot from the program showing a frog playing a ukulele. This view includes textures."},{"fileName":"screenshot2.png","description":"A screenshot from the program showing a frog playing a ukulele. This view includes shading."},{"fileName":"screenshot3.png","description":"A close-up screenshot from the program showing a frog playing a ukulele. This view includes textures."}],"videos":[{"videoHost":"youtube","id":"r8-zo-j-7PU","description":"A video showing an animated frog playing a ukulele."}],"content":"As part of a grahics course at the University of Washington, Levi co-developed a model and animation of a frog playing\na ukulele.\n\n_OpenGL with C++_"},{"id":"voicebox-technologies","titleShort":"Audio\nSignal\nProcessing","titleLong":"Audio Signal Processing","urls":{"homepage":"http://voicebox.com"},"jobTitle":"Summer Intern (Software Engineer)","date":"2011","categories":["work","intern","c","c++"],"images":[{"fileName":"spectrogram.jpg","description":"A spectrogram with its corresponding waveform."}],"videos":[],"content":"_[VoiceBox Technologies][main-url] is a company focused on conversational speech recognition, search, and information\nmanagement._\n\nLevi integrated noise-suppression functionality from an ETSI standard into VBT’s pre-existing\n[Voice Activity Detection][vad-url] software and tuned it for optimal performance.\n\n_C with C++ wrappers_\n\n[main-url]: http://voicebox.com/\n[vad-url]: http://en.wikipedia.org/wiki/Voice_activity_detection"},{"id":"wedding-invite","titleShort":"Web App:\nWedding\nSite","titleLong":"Wedding Invite and RSVP System","urls":{"demo":"http://jackieandlevi.com/wedding/invite","github":"https://github.com/levisl176/wedding-invite"},"jobTitle":"","date":"2012","categories":["side-project","web","web-site","front-end","php","jquery","animations"],"images":[{"fileName":"screenshot1.png","description":"The landing view."},{"fileName":"screenshot2.png","description":"As the user moves the mouse invard, or touches the envelope, different navigational cards slide outward from under the envelope."},{"fileName":"screenshot4.png","description":"The RSVP card."},{"fileName":"screenshot5.png","description":"A card that tells the time of the wedding and shows a countdown."},{"fileName":"screenshot6.png","description":"A card that names the two people getting married."},{"fileName":"screenshot7.png","description":"A card that describes the location of the celebration."},{"fileName":"screenshot8.png","description":"A card that describes the specifics of the celebration."}],"videos":[],"content":"#### A wedding invite and RSVP system\n\nLevi developed this simple web app as the invite and RSVP system for his and [Jackie's][jackie-url] wedding.\n\n_PHP and jQuery_\n\n\n[main-url]: http://jackieandlevi.com/wedding/invite\n[jackie-url]: http://jackieandlevi.com/jackie"}]}